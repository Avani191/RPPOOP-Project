{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Avani191/RPPOOP-Project/blob/main/proj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKiB0NtTWlKX",
        "outputId": "010bdb87-82ba-4c1a-fede-2ad9a32ca3a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOGDgSXxDqBT",
        "outputId": "c1f02340-8ebe-4d32-83d1-03a99825ef85"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1QB4XDCW-03",
        "outputId": "e54788d0-d36b-4d6d-bb71-cbbfbdb9991c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmYQkYZeX7FI",
        "outputId": "eb068b48-3c76-424c-b58e-00a038fc3236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting twilio\n",
            "  Downloading twilio-8.2.2-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from twilio) (2022.7.1)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from twilio) (2.27.1)\n",
            "Collecting PyJWT<3.0.0,>=2.0.0 (from twilio)\n",
            "  Downloading PyJWT-2.7.0-py3-none-any.whl (22 kB)\n",
            "Collecting aiohttp>=3.8.4 (from twilio)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp-retry>=2.8.3 (from twilio)\n",
            "  Downloading aiohttp_retry-2.8.3-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.4->twilio) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp>=3.8.4->twilio)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp>=3.8.4->twilio)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp>=3.8.4->twilio)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp>=3.8.4->twilio)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp>=3.8.4->twilio)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->twilio) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->twilio) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.0.0->twilio) (3.4)\n",
            "Installing collected packages: PyJWT, multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, aiohttp-retry, twilio\n",
            "Successfully installed PyJWT-2.7.0 aiohttp-3.8.4 aiohttp-retry-2.8.3 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 twilio-8.2.2 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "!pip install twilio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Zoi_3siGX7Pi"
      },
      "outputs": [],
      "source": [
        "from twilio.rest import Client\n",
        "\n",
        "account_sid = 'AC225bee69b87720fa00cc282e477d8998'\n",
        "auth_token = 'a406d3d14fbe6e7414103a98490667b3'\n",
        "client = Client(account_sid, auth_token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG46DR3BWLC4",
        "outputId": "94775ddb-c77e-4427-93ef-c5ca267c7b01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "<ipython-input-6-42bd4c96de47>:68: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  training = np.array(training)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data created\n",
            "Epoch 1/300\n",
            "35/35 [==============================] - 1s 3ms/step - loss: 3.7133 - accuracy: 0.0289\n",
            "Epoch 2/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 3.6281 - accuracy: 0.0809\n",
            "Epoch 3/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 3.5293 - accuracy: 0.0925\n",
            "Epoch 4/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 3.4209 - accuracy: 0.1214\n",
            "Epoch 5/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 3.3835 - accuracy: 0.1618\n",
            "Epoch 6/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 3.2982 - accuracy: 0.1561\n",
            "Epoch 7/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 3.0345 - accuracy: 0.2081\n",
            "Epoch 8/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.9766 - accuracy: 0.2254\n",
            "Epoch 9/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.7733 - accuracy: 0.2486\n",
            "Epoch 10/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.7521 - accuracy: 0.2197\n",
            "Epoch 11/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.5782 - accuracy: 0.3006\n",
            "Epoch 12/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.5385 - accuracy: 0.2948\n",
            "Epoch 13/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.4436 - accuracy: 0.3121\n",
            "Epoch 14/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.2266 - accuracy: 0.3468\n",
            "Epoch 15/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.2023 - accuracy: 0.3815\n",
            "Epoch 16/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 2.0994 - accuracy: 0.4046\n",
            "Epoch 17/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.0349 - accuracy: 0.4566\n",
            "Epoch 18/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 2.0061 - accuracy: 0.4393\n",
            "Epoch 19/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.8501 - accuracy: 0.4277\n",
            "Epoch 20/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.8408 - accuracy: 0.4220\n",
            "Epoch 21/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.6580 - accuracy: 0.5434\n",
            "Epoch 22/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.4620 - accuracy: 0.5665\n",
            "Epoch 23/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.3628 - accuracy: 0.5665\n",
            "Epoch 24/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.5708 - accuracy: 0.4971\n",
            "Epoch 25/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.5712 - accuracy: 0.5549\n",
            "Epoch 26/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.2932 - accuracy: 0.6012\n",
            "Epoch 27/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.4186 - accuracy: 0.6012\n",
            "Epoch 28/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 1.1647 - accuracy: 0.6358\n",
            "Epoch 29/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0995 - accuracy: 0.6936\n",
            "Epoch 30/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.1773 - accuracy: 0.6243\n",
            "Epoch 31/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 1.0148 - accuracy: 0.7283\n",
            "Epoch 32/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9576 - accuracy: 0.6936\n",
            "Epoch 33/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.8824 - accuracy: 0.7225\n",
            "Epoch 34/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9007 - accuracy: 0.7283\n",
            "Epoch 35/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9314 - accuracy: 0.7341\n",
            "Epoch 36/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.9353 - accuracy: 0.7225\n",
            "Epoch 37/300\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.9177 - accuracy: 0.7168\n",
            "Epoch 38/300\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.8253 - accuracy: 0.7514\n",
            "Epoch 39/300\n",
            "35/35 [==============================] - 0s 6ms/step - loss: 0.7949 - accuracy: 0.7688\n",
            "Epoch 40/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.7221 - accuracy: 0.7977\n",
            "Epoch 41/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.7665 - accuracy: 0.7283\n",
            "Epoch 42/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.7215 - accuracy: 0.7977\n",
            "Epoch 43/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6464 - accuracy: 0.8035\n",
            "Epoch 44/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.7032 - accuracy: 0.7630\n",
            "Epoch 45/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.6215 - accuracy: 0.8382\n",
            "Epoch 46/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6420 - accuracy: 0.8092\n",
            "Epoch 47/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.8266\n",
            "Epoch 48/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.8497\n",
            "Epoch 49/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5998 - accuracy: 0.7977\n",
            "Epoch 50/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.7163 - accuracy: 0.7803\n",
            "Epoch 51/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5440 - accuracy: 0.8208\n",
            "Epoch 52/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6245 - accuracy: 0.7861\n",
            "Epoch 53/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6355 - accuracy: 0.7861\n",
            "Epoch 54/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.5840 - accuracy: 0.8382\n",
            "Epoch 55/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.8671\n",
            "Epoch 56/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.8092\n",
            "Epoch 57/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.8382\n",
            "Epoch 58/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4864 - accuracy: 0.8497\n",
            "Epoch 59/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8902\n",
            "Epoch 60/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.8960\n",
            "Epoch 61/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.8208\n",
            "Epoch 62/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.8613\n",
            "Epoch 63/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4603 - accuracy: 0.8324\n",
            "Epoch 64/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4937 - accuracy: 0.8382\n",
            "Epoch 65/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4047 - accuracy: 0.8786\n",
            "Epoch 66/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3943 - accuracy: 0.8844\n",
            "Epoch 67/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4461 - accuracy: 0.8555\n",
            "Epoch 68/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.8555\n",
            "Epoch 69/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8844\n",
            "Epoch 70/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3856 - accuracy: 0.8844\n",
            "Epoch 71/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.8439\n",
            "Epoch 72/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.8555\n",
            "Epoch 73/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3318 - accuracy: 0.9133\n",
            "Epoch 74/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3473 - accuracy: 0.8960\n",
            "Epoch 75/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3736 - accuracy: 0.9017\n",
            "Epoch 76/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2812 - accuracy: 0.8902\n",
            "Epoch 77/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3444 - accuracy: 0.8902\n",
            "Epoch 78/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2828 - accuracy: 0.9364\n",
            "Epoch 79/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.9075\n",
            "Epoch 80/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3961 - accuracy: 0.8671\n",
            "Epoch 81/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3901 - accuracy: 0.8786\n",
            "Epoch 82/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3716 - accuracy: 0.8671\n",
            "Epoch 83/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3278 - accuracy: 0.8902\n",
            "Epoch 84/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3741 - accuracy: 0.8613\n",
            "Epoch 85/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.8497\n",
            "Epoch 86/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3454 - accuracy: 0.8902\n",
            "Epoch 87/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2906 - accuracy: 0.8902\n",
            "Epoch 88/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2892 - accuracy: 0.8960\n",
            "Epoch 89/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2739 - accuracy: 0.9017\n",
            "Epoch 90/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.4269 - accuracy: 0.8555\n",
            "Epoch 91/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3735 - accuracy: 0.8728\n",
            "Epoch 92/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3478 - accuracy: 0.8728\n",
            "Epoch 93/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3369 - accuracy: 0.8960\n",
            "Epoch 94/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3482 - accuracy: 0.8844\n",
            "Epoch 95/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3301 - accuracy: 0.8786\n",
            "Epoch 96/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3680 - accuracy: 0.8786\n",
            "Epoch 97/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.9075\n",
            "Epoch 98/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2215 - accuracy: 0.9133\n",
            "Epoch 99/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2766 - accuracy: 0.8844\n",
            "Epoch 100/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.8786\n",
            "Epoch 101/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2708 - accuracy: 0.9306\n",
            "Epoch 102/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3570 - accuracy: 0.8671\n",
            "Epoch 103/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2900 - accuracy: 0.9133\n",
            "Epoch 104/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.9075\n",
            "Epoch 105/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8902\n",
            "Epoch 106/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.9191\n",
            "Epoch 107/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.9075\n",
            "Epoch 108/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2662 - accuracy: 0.9017\n",
            "Epoch 109/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2885 - accuracy: 0.8902\n",
            "Epoch 110/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2523 - accuracy: 0.9249\n",
            "Epoch 111/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3659 - accuracy: 0.8671\n",
            "Epoch 112/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2604 - accuracy: 0.9191\n",
            "Epoch 113/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8902\n",
            "Epoch 114/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.9075\n",
            "Epoch 115/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3125 - accuracy: 0.9017\n",
            "Epoch 116/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8960\n",
            "Epoch 117/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8902\n",
            "Epoch 118/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2612 - accuracy: 0.8960\n",
            "Epoch 119/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2890 - accuracy: 0.9133\n",
            "Epoch 120/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2754 - accuracy: 0.8786\n",
            "Epoch 121/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2763 - accuracy: 0.8960\n",
            "Epoch 122/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.9133\n",
            "Epoch 123/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2060 - accuracy: 0.9249\n",
            "Epoch 124/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2475 - accuracy: 0.9075\n",
            "Epoch 125/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3048 - accuracy: 0.9017\n",
            "Epoch 126/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2777 - accuracy: 0.8902\n",
            "Epoch 127/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2837 - accuracy: 0.9133\n",
            "Epoch 128/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3495 - accuracy: 0.8902\n",
            "Epoch 129/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2390 - accuracy: 0.9133\n",
            "Epoch 130/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8902\n",
            "Epoch 131/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2422 - accuracy: 0.9133\n",
            "Epoch 132/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2723 - accuracy: 0.9133\n",
            "Epoch 133/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2933 - accuracy: 0.8960\n",
            "Epoch 134/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2645 - accuracy: 0.9306\n",
            "Epoch 135/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2637 - accuracy: 0.9075\n",
            "Epoch 136/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.9017\n",
            "Epoch 137/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2482 - accuracy: 0.9191\n",
            "Epoch 138/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3170 - accuracy: 0.8960\n",
            "Epoch 139/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.9017\n",
            "Epoch 140/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2554 - accuracy: 0.9191\n",
            "Epoch 141/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2211 - accuracy: 0.9249\n",
            "Epoch 142/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2814 - accuracy: 0.8902\n",
            "Epoch 143/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2399 - accuracy: 0.9191\n",
            "Epoch 144/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3346 - accuracy: 0.8786\n",
            "Epoch 145/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2048 - accuracy: 0.9422\n",
            "Epoch 146/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2300 - accuracy: 0.9422\n",
            "Epoch 147/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1985 - accuracy: 0.9364\n",
            "Epoch 148/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1646 - accuracy: 0.9306\n",
            "Epoch 149/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2379 - accuracy: 0.9249\n",
            "Epoch 150/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1775 - accuracy: 0.9422\n",
            "Epoch 151/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.3008 - accuracy: 0.8960\n",
            "Epoch 152/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2508 - accuracy: 0.9133\n",
            "Epoch 153/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2704 - accuracy: 0.9249\n",
            "Epoch 154/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2325 - accuracy: 0.9075\n",
            "Epoch 155/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2137 - accuracy: 0.9422\n",
            "Epoch 156/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2955 - accuracy: 0.8844\n",
            "Epoch 157/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.9249\n",
            "Epoch 158/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1639 - accuracy: 0.9653\n",
            "Epoch 159/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2747 - accuracy: 0.9017\n",
            "Epoch 160/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.9422\n",
            "Epoch 161/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2766 - accuracy: 0.8844\n",
            "Epoch 162/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2297 - accuracy: 0.9306\n",
            "Epoch 163/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2420 - accuracy: 0.9017\n",
            "Epoch 164/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1936 - accuracy: 0.9422\n",
            "Epoch 165/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2282 - accuracy: 0.9075\n",
            "Epoch 166/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2470 - accuracy: 0.9075\n",
            "Epoch 167/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2838 - accuracy: 0.8902\n",
            "Epoch 168/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.3196 - accuracy: 0.8902\n",
            "Epoch 169/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2592 - accuracy: 0.8902\n",
            "Epoch 170/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2350 - accuracy: 0.9191\n",
            "Epoch 171/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2816 - accuracy: 0.9017\n",
            "Epoch 172/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1704 - accuracy: 0.9422\n",
            "Epoch 173/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1588 - accuracy: 0.9480\n",
            "Epoch 174/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2493 - accuracy: 0.9133\n",
            "Epoch 175/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2719 - accuracy: 0.8960\n",
            "Epoch 176/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2542 - accuracy: 0.9191\n",
            "Epoch 177/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2806 - accuracy: 0.9249\n",
            "Epoch 178/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2837 - accuracy: 0.9191\n",
            "Epoch 179/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2444 - accuracy: 0.8960\n",
            "Epoch 180/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2138 - accuracy: 0.9249\n",
            "Epoch 181/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2117 - accuracy: 0.9133\n",
            "Epoch 182/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2001 - accuracy: 0.9191\n",
            "Epoch 183/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2517 - accuracy: 0.9133\n",
            "Epoch 184/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2477 - accuracy: 0.8844\n",
            "Epoch 185/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2247 - accuracy: 0.9133\n",
            "Epoch 186/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2613 - accuracy: 0.9364\n",
            "Epoch 187/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2275 - accuracy: 0.9191\n",
            "Epoch 188/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1843 - accuracy: 0.9364\n",
            "Epoch 189/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2406 - accuracy: 0.9133\n",
            "Epoch 190/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2367 - accuracy: 0.9249\n",
            "Epoch 191/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2148 - accuracy: 0.9133\n",
            "Epoch 192/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2268 - accuracy: 0.9306\n",
            "Epoch 193/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1718 - accuracy: 0.9306\n",
            "Epoch 194/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2527 - accuracy: 0.9075\n",
            "Epoch 195/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2744 - accuracy: 0.9075\n",
            "Epoch 196/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2328 - accuracy: 0.9249\n",
            "Epoch 197/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2260 - accuracy: 0.9075\n",
            "Epoch 198/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1319 - accuracy: 0.9595\n",
            "Epoch 199/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1779 - accuracy: 0.9249\n",
            "Epoch 200/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2251 - accuracy: 0.9249\n",
            "Epoch 201/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1906 - accuracy: 0.9364\n",
            "Epoch 202/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2004 - accuracy: 0.9422\n",
            "Epoch 203/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2739 - accuracy: 0.8960\n",
            "Epoch 204/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2276 - accuracy: 0.9075\n",
            "Epoch 205/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2265 - accuracy: 0.9191\n",
            "Epoch 206/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2417 - accuracy: 0.9133\n",
            "Epoch 207/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2284 - accuracy: 0.9306\n",
            "Epoch 208/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3022 - accuracy: 0.9017\n",
            "Epoch 209/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1899 - accuracy: 0.9133\n",
            "Epoch 210/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2481 - accuracy: 0.9017\n",
            "Epoch 211/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1858 - accuracy: 0.9306\n",
            "Epoch 212/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1880 - accuracy: 0.9422\n",
            "Epoch 213/300\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.1897 - accuracy: 0.9306\n",
            "Epoch 214/300\n",
            "35/35 [==============================] - 0s 5ms/step - loss: 0.2237 - accuracy: 0.9133\n",
            "Epoch 215/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2778 - accuracy: 0.8671\n",
            "Epoch 216/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1628 - accuracy: 0.9480\n",
            "Epoch 217/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1484 - accuracy: 0.9364\n",
            "Epoch 218/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1438 - accuracy: 0.9480\n",
            "Epoch 219/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2156 - accuracy: 0.9422\n",
            "Epoch 220/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1468 - accuracy: 0.9249\n",
            "Epoch 221/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1686 - accuracy: 0.9364\n",
            "Epoch 222/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1803 - accuracy: 0.9249\n",
            "Epoch 223/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1339 - accuracy: 0.9595\n",
            "Epoch 224/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2162 - accuracy: 0.9364\n",
            "Epoch 225/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2776 - accuracy: 0.9017\n",
            "Epoch 226/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1984 - accuracy: 0.9364\n",
            "Epoch 227/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2622 - accuracy: 0.9133\n",
            "Epoch 228/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1782 - accuracy: 0.9422\n",
            "Epoch 229/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2080 - accuracy: 0.9133\n",
            "Epoch 230/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1694 - accuracy: 0.9306\n",
            "Epoch 231/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2109 - accuracy: 0.9017\n",
            "Epoch 232/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2116 - accuracy: 0.9191\n",
            "Epoch 233/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1996 - accuracy: 0.9364\n",
            "Epoch 234/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2444 - accuracy: 0.9075\n",
            "Epoch 235/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1986 - accuracy: 0.9191\n",
            "Epoch 236/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.8902\n",
            "Epoch 237/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2080 - accuracy: 0.9249\n",
            "Epoch 238/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1758 - accuracy: 0.9249\n",
            "Epoch 239/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1469 - accuracy: 0.9364\n",
            "Epoch 240/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9306\n",
            "Epoch 241/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1940 - accuracy: 0.9422\n",
            "Epoch 242/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2066 - accuracy: 0.9249\n",
            "Epoch 243/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2196 - accuracy: 0.9191\n",
            "Epoch 244/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2348 - accuracy: 0.9133\n",
            "Epoch 245/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1815 - accuracy: 0.9133\n",
            "Epoch 246/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1558 - accuracy: 0.9364\n",
            "Epoch 247/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.2178 - accuracy: 0.9422\n",
            "Epoch 248/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1841 - accuracy: 0.9191\n",
            "Epoch 249/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1706 - accuracy: 0.9364\n",
            "Epoch 250/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2187 - accuracy: 0.9306\n",
            "Epoch 251/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1766 - accuracy: 0.9364\n",
            "Epoch 252/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1936 - accuracy: 0.9364\n",
            "Epoch 253/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1339 - accuracy: 0.9480\n",
            "Epoch 254/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1803 - accuracy: 0.9075\n",
            "Epoch 255/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2061 - accuracy: 0.9191\n",
            "Epoch 256/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.1558 - accuracy: 0.9480\n",
            "Epoch 257/300\n",
            "35/35 [==============================] - 0s 4ms/step - loss: 0.2187 - accuracy: 0.9306\n",
            "Epoch 258/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1823 - accuracy: 0.9306\n",
            "Epoch 259/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1331 - accuracy: 0.9480\n",
            "Epoch 260/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1481 - accuracy: 0.9538\n",
            "Epoch 261/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1767 - accuracy: 0.9306\n",
            "Epoch 262/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1866 - accuracy: 0.9249\n",
            "Epoch 263/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1504 - accuracy: 0.9364\n",
            "Epoch 264/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1792 - accuracy: 0.9422\n",
            "Epoch 265/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1476 - accuracy: 0.9364\n",
            "Epoch 266/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1986 - accuracy: 0.9422\n",
            "Epoch 267/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1788 - accuracy: 0.9249\n",
            "Epoch 268/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.9422\n",
            "Epoch 269/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2095 - accuracy: 0.9249\n",
            "Epoch 270/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9249\n",
            "Epoch 271/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1894 - accuracy: 0.9249\n",
            "Epoch 272/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1566 - accuracy: 0.9364\n",
            "Epoch 273/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2115 - accuracy: 0.9191\n",
            "Epoch 274/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1839 - accuracy: 0.9306\n",
            "Epoch 275/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1556 - accuracy: 0.9538\n",
            "Epoch 276/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1851 - accuracy: 0.9191\n",
            "Epoch 277/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1946 - accuracy: 0.9191\n",
            "Epoch 278/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2452 - accuracy: 0.9075\n",
            "Epoch 279/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2510 - accuracy: 0.9133\n",
            "Epoch 280/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1808 - accuracy: 0.9306\n",
            "Epoch 281/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.9364\n",
            "Epoch 282/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2056 - accuracy: 0.9133\n",
            "Epoch 283/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.9364\n",
            "Epoch 284/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1873 - accuracy: 0.9422\n",
            "Epoch 285/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1732 - accuracy: 0.9422\n",
            "Epoch 286/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1558 - accuracy: 0.9538\n",
            "Epoch 287/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1501 - accuracy: 0.9480\n",
            "Epoch 288/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1822 - accuracy: 0.9364\n",
            "Epoch 289/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9133\n",
            "Epoch 290/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1952 - accuracy: 0.9306\n",
            "Epoch 291/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.9306\n",
            "Epoch 292/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9306\n",
            "Epoch 293/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9364\n",
            "Epoch 294/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2215 - accuracy: 0.9191\n",
            "Epoch 295/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2096 - accuracy: 0.9133\n",
            "Epoch 296/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1801 - accuracy: 0.9422\n",
            "Epoch 297/300\n",
            "35/35 [==============================] - 0s 3ms/step - loss: 0.1767 - accuracy: 0.9306\n",
            "Epoch 298/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1790 - accuracy: 0.9249\n",
            "Epoch 299/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.2383 - accuracy: 0.9133\n",
            "Epoch 300/300\n",
            "35/35 [==============================] - 0s 2ms/step - loss: 0.1762 - accuracy: 0.9480\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "from tensorflow.keras.models import Sequential\n",
        "#from keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import random\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import json\n",
        "import pickle\n",
        "\n",
        "words=[]\n",
        "classes = []\n",
        "documents = []\n",
        "ignore_letters = ['!', '?', ',', '.']\n",
        "intents_file = open(\"/content/drive/MyDrive/RPPOOPMiniProject/intents.json\").read()\n",
        "intents = json.loads(intents_file)\n",
        "\n",
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "        word = nltk.word_tokenize(pattern)\n",
        "        words.extend(word)\n",
        "        #add documents in the corpus\n",
        "        documents.append((word, intent['tag']))\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])\n",
        "#print(documents)\n",
        "# lemmaztize and lower each word and remove duplicates\n",
        "words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_letters]\n",
        "words = sorted(list(set(words)))\n",
        "# sort classes\n",
        "classes = sorted(list(set(classes)))\n",
        "# documents = combination between patterns and intents\n",
        "#print (len(documents), \"documents\")\n",
        "# classes = intents\n",
        "#print (len(classes), \"classes\", classes)\n",
        "# words = all words, vocabulary\n",
        "#print (len(words), \"unique lemmatized words\", words)\n",
        "\n",
        "pickle.dump(words,open('words.pkl','wb'))\n",
        "pickle.dump(classes,open('classes.pkl','wb'))\n",
        "\n",
        "# create our training data\n",
        "training = []\n",
        "output_empty = [0] * len(classes)\n",
        "# training set, bag of words for each sentence\n",
        "for doc in documents:\n",
        "    # initialize our bag of words\n",
        "    bag = []\n",
        "    pattern_words = doc[0]\n",
        "    # lemmatize each word - create base word, in attempt to represent related words\n",
        "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
        "    # create our bag of words array with 1, if word match found in current pattern\n",
        "    for word in words:\n",
        "        bag.append(1) if word in pattern_words else bag.append(0)\n",
        "        \n",
        "    # output is a '0' for each tag and '1' for current tag (for each pattern)\n",
        "    output_row = list(output_empty)\n",
        "    output_row[classes.index(doc[1])] = 1\n",
        "    \n",
        "    training.append([bag, output_row])\n",
        "\n",
        "random.shuffle(training)\n",
        "training = np.array(training)\n",
        "# create train and test lists. X - patterns, Y - intents\n",
        "train_x = list(training[:,0])\n",
        "train_y = list(training[:,1])\n",
        "print(\"Training data created\")\n",
        "\n",
        "# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n",
        "# equal to number of intents to predict output intent with softmax\n",
        "# Create the model\n",
        "model = Sequential([\n",
        "    Dense(128, input_shape=(len(train_x[0]),), activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(len(train_y[0]), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = SGD(learning_rate=0.01, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "history = model.fit(np.array(train_x), np.array(train_y), epochs=300, batch_size=5, verbose=1)\n",
        "\n",
        "# Save the model\n",
        "model.save('WBot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PTN0aWjcWL7X"
      },
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('WBot')\n",
        "intents = json.loads(open(\"/content/drive/MyDrive/RPPOOPMiniProject/intents.json\").read())\n",
        "words = pickle.load(open(\"words.pkl\",'rb'))\n",
        "classes = pickle.load(open(\"classes.pkl\",'rb'))\n",
        "def clean_up_sentence(sentence):\n",
        "    # tokenize the pattern - splitting words into array\n",
        "    sentence_words = nltk.word_tokenize(sentence)\n",
        "    # stemming every word - reducing to base form\n",
        "    sentence_words = [lemmatizer.lemmatize(word.lower()) for word in sentence_words]\n",
        "    return sentence_words\n",
        "# return bag of words array: 0 or 1 for words that exist in sentence\n",
        "def bag_of_words(sentence, words, show_details=True):\n",
        "    # tokenizing patterns\n",
        "    sentence_words = clean_up_sentence(sentence)\n",
        "    # bag of words - vocabulary matrix\n",
        "    bag = [0]*len(words)  \n",
        "    for s in sentence_words:\n",
        "        for i,word in enumerate(words):\n",
        "            if word == s: \n",
        "                # assign 1 if current word is in the vocabulary position\n",
        "                bag[i] = 1\n",
        "                #if show_details:\n",
        "                    #print (\"found in bag: %s\" % word)\n",
        "    return(np.array(bag))\n",
        "def predict_class(sentence):\n",
        "    # filter below  threshold predictions\n",
        "    p = bag_of_words(sentence, words,show_details=False)\n",
        "    res = model.predict(np.array([p]))[0]\n",
        "    ERROR_THRESHOLD = 0.25\n",
        "    results = [[i,r] for i,r in enumerate(res) if r>ERROR_THRESHOLD]\n",
        "    # sorting strength probability\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    return_list = []\n",
        "    for r in results:\n",
        "        return_list.append({\"intent\": classes[r[0]], \"probability\": str(r[1])})\n",
        "    return return_list\n",
        "def getResponse(ints, intents_json):\n",
        "    tag = ints[0]['intent']\n",
        "    list_of_intents = intents_json['intents']\n",
        "    for i in list_of_intents: \n",
        "        if(i['tag']== tag):\n",
        "            result = random.choice(i['responses'])\n",
        "            break\n",
        "    return result\n",
        "\n",
        "def responsed(msg1):\n",
        "   # msg.append(msg1)\n",
        "    ints = predict_class(msg1)\n",
        "    response = getResponse(ints, intents)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yDjhJXBcWP5E"
      },
      "outputs": [],
      "source": [
        "class chatbot:\n",
        "    def __init__(self):\n",
        "        self.name = \"Stark\"\n",
        "        self.msgs = []\n",
        "        \n",
        "    def conversation(self, message):\n",
        "        print(f\"Chatbot : Hey there, How are you doing today? I am {self.name}.\\n\")\n",
        "        flag = True\n",
        "        while(flag == True):\n",
        "            m = input(\"User : \")\n",
        "            m = m.lower()\n",
        "            self.msgs.append(m)\n",
        "            if len(self.msgs) > 15:\n",
        "                self.msgs = self.msgs[-15:]\n",
        "            if(m == \"bye\" ):\n",
        "                flag = False\n",
        "                response = responsed(m)\n",
        "                print(\"Chatbot : \"+response)\n",
        "            else:\n",
        "                response = responsed(m)\n",
        "                if(response ==\"Here are some songs for you\" or response == \"right here for you\" ):\n",
        "                    print(\"Chatbot : \"+response)\n",
        "                    response = self.song_emotion()\n",
        "                print(\"Chatbot : \"+response)\n",
        "                \n",
        "    def song_emotion(self):\n",
        "        sid = SentimentIntensityAnalyzer()\n",
        "        songs = {}\n",
        "\n",
        "        for msg in self.msgs:\n",
        "            sentiment_scores = sid.polarity_scores(msg)\n",
        "            emotion = max(sentiment_scores, key=sentiment_scores.get)\n",
        "            if(emotion == \"neg\"):\n",
        "                emotion = \"sad\"\n",
        "           # print(emotion)\n",
        "\n",
        "            url = f\"http://ws.audioscrobbler.com/2.0/?method=tag.gettoptracks&tag={emotion}&api_key=715156ee90d656693aaf300097923cbd&format=json&limit=20\"\n",
        "            response = requests.get(url)\n",
        "            payload = response.json()\n",
        "\n",
        "            for i in range(10):\n",
        "                r = payload['tracks']['track'][i]\n",
        "                songs[r['name']] = r['url']\n",
        "\n",
        "        song_urls = list(songs.values())\n",
        "\n",
        "        if len(song_urls) > 5:\n",
        "            random.shuffle(song_urls)\n",
        "            song_urls = song_urls[:5]\n",
        "\n",
        "        return '\\n'.join(song_urls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkA5bzEJWTeB"
      },
      "outputs": [],
      "source": [
        "#c = chatbot()\n",
        "#c.name\n",
        "#c.conversation()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from twilio.twiml.messaging_response import MessagingResponse\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "c = chatbot()\n",
        "c.name\n",
        "\n",
        "@app.route('/sms', methods=['POST'])\n",
        "def sms():\n",
        "    message_body = request.form['Body']\n",
        "    response = c.conversation(message_body)\n",
        "    send_message(response)\n",
        "\n",
        "def send_message(message):\n",
        "    client.messages.create(\n",
        "        body=message\n",
        "    )\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    nltk.download('vader_lexicon')\n",
        "    app.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLTCMgnI9FVw",
        "outputId": "053f8d8a-3564-4510-a88e-19e1356fc865"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip freeze\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7dz4RIrOxO9",
        "outputId": "abbc8fdd-8ce5-4da8-f24a-178e21875278"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==1.4.0\n",
            "aiohttp==3.8.4\n",
            "aiohttp-retry==2.8.3\n",
            "aiosignal==1.3.1\n",
            "alabaster==0.7.13\n",
            "albumentations==1.2.1\n",
            "altair==4.2.2\n",
            "anyio==3.6.2\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==21.3.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "array-record==0.2.0\n",
            "arviz==0.15.1\n",
            "astropy==5.2.2\n",
            "astunparse==1.6.3\n",
            "async-timeout==4.0.2\n",
            "attrs==23.1.0\n",
            "audioread==3.0.0\n",
            "autograd==1.5\n",
            "Babel==2.12.1\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.11.2\n",
            "bleach==6.0.0\n",
            "blis==0.7.9\n",
            "blosc2==2.0.0\n",
            "bokeh==2.4.3\n",
            "branca==0.6.0\n",
            "build==0.10.0\n",
            "CacheControl==0.12.11\n",
            "cached-property==1.5.2\n",
            "cachetools==5.3.0\n",
            "catalogue==2.0.8\n",
            "certifi==2022.12.7\n",
            "cffi==1.15.1\n",
            "chardet==4.0.0\n",
            "charset-normalizer==2.0.12\n",
            "chex==0.1.7\n",
            "click==8.1.3\n",
            "cloudpickle==2.2.1\n",
            "cmake==3.25.2\n",
            "cmdstanpy==1.1.0\n",
            "colorcet==3.0.1\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "confection==0.0.4\n",
            "cons==0.4.5\n",
            "contextlib2==0.6.0.post1\n",
            "contourpy==1.0.7\n",
            "convertdate==2.4.0\n",
            "cryptography==40.0.2\n",
            "cufflinks==0.17.3\n",
            "cvxopt==1.3.0\n",
            "cvxpy==1.3.1\n",
            "cycler==0.11.0\n",
            "cymem==2.0.7\n",
            "Cython==0.29.34\n",
            "dask==2022.12.1\n",
            "datascience==0.17.6\n",
            "db-dtypes==1.1.1\n",
            "dbus-python==1.2.16\n",
            "debugpy==1.6.6\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "distributed==2022.12.1\n",
            "dlib==19.24.1\n",
            "dm-tree==0.1.8\n",
            "docutils==0.16\n",
            "dopamine-rl==4.0.6\n",
            "duckdb==0.7.1\n",
            "earthengine-api==0.1.350\n",
            "easydict==1.10\n",
            "ecos==2.0.12\n",
            "editdistance==0.6.2\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl#sha256=0964370218b7e1672a30ac50d72cdc6b16f7c867496f1d60925691188f4d2510\n",
            "entrypoints==0.4\n",
            "ephem==4.1.4\n",
            "et-xmlfile==1.1.0\n",
            "etils==1.2.0\n",
            "etuples==0.3.8\n",
            "exceptiongroup==1.1.1\n",
            "fastai==2.7.12\n",
            "fastcore==1.5.29\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.16.3\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.1\n",
            "filelock==3.12.0\n",
            "firebase-admin==5.3.0\n",
            "Flask==2.2.4\n",
            "flatbuffers==23.3.3\n",
            "flax==0.6.9\n",
            "folium==0.14.0\n",
            "fonttools==4.39.3\n",
            "frozendict==2.3.7\n",
            "frozenlist==1.3.3\n",
            "fsspec==2023.4.0\n",
            "future==0.18.3\n",
            "gast==0.4.0\n",
            "GDAL==3.3.2\n",
            "gdown==4.6.6\n",
            "gensim==4.3.1\n",
            "geographiclib==2.0\n",
            "geopy==2.3.0\n",
            "gin-config==0.5.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==2.11.0\n",
            "google-api-python-client==2.84.0\n",
            "google-auth==2.17.3\n",
            "google-auth-httplib2==0.1.0\n",
            "google-auth-oauthlib==1.0.0\n",
            "google-cloud-bigquery==3.9.0\n",
            "google-cloud-bigquery-storage==2.19.1\n",
            "google-cloud-core==2.3.2\n",
            "google-cloud-datastore==2.15.1\n",
            "google-cloud-firestore==2.11.0\n",
            "google-cloud-language==2.9.1\n",
            "google-cloud-storage==2.8.0\n",
            "google-cloud-translate==3.11.1\n",
            "google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz#sha256=335a15e5632c1a52a8db6af4cee46dd49aab81cfb8e62857ac00a3ab7da97c2b\n",
            "google-crc32c==1.5.0\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.5.0\n",
            "googleapis-common-protos==1.59.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.20.1\n",
            "greenlet==2.0.2\n",
            "grpcio==1.54.0\n",
            "grpcio-status==1.48.2\n",
            "gspread==3.4.2\n",
            "gspread-dataframe==3.0.8\n",
            "gym==0.25.2\n",
            "gym-notices==0.0.8\n",
            "h5netcdf==1.1.0\n",
            "h5py==3.8.0\n",
            "holidays==0.25\n",
            "holoviews==1.15.4\n",
            "html5lib==1.1\n",
            "httpimport==1.3.0\n",
            "httplib2==0.21.0\n",
            "humanize==4.6.0\n",
            "hyperopt==0.2.7\n",
            "idna==3.4\n",
            "imageio==2.25.1\n",
            "imageio-ffmpeg==0.4.8\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.10.1\n",
            "imgaug==0.4.0\n",
            "importlib-resources==5.12.0\n",
            "imutils==0.5.4\n",
            "inflect==6.0.4\n",
            "iniconfig==2.0.0\n",
            "intel-openmp==2023.1.0\n",
            "ipykernel==5.5.6\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.4.1\n",
            "ipywidgets==7.7.1\n",
            "itsdangerous==2.1.2\n",
            "jax==0.4.10\n",
            "jaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.4.10+cuda11.cudnn86-cp310-cp310-manylinux2014_x86_64.whl#sha256=fe53205ef12727c80ed5ac2d4506d6732c0c3db69ede4565a7d4df98e609af84\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.2\n",
            "joblib==1.2.0\n",
            "jsonpickle==3.0.1\n",
            "jsonschema==4.3.3\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter-server==1.24.0\n",
            "jupyter_core==5.3.0\n",
            "jupyterlab-pygments==0.2.2\n",
            "jupyterlab-widgets==3.0.7\n",
            "kaggle==1.5.13\n",
            "keras==2.12.0\n",
            "kiwisolver==1.4.4\n",
            "korean-lunar-calendar==0.3.1\n",
            "langcodes==3.3.0\n",
            "lazy_loader==0.2\n",
            "libclang==16.0.0\n",
            "librosa==0.10.0.post2\n",
            "lightgbm==3.3.5\n",
            "lit==16.0.5\n",
            "llvmlite==0.39.1\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.5\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.9.2\n",
            "Markdown==3.4.3\n",
            "markdown-it-py==2.2.0\n",
            "MarkupSafe==2.1.2\n",
            "matplotlib==3.7.1\n",
            "matplotlib-inline==0.1.6\n",
            "matplotlib-venn==0.11.9\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.3\n",
            "missingno==0.5.2\n",
            "mistune==0.8.4\n",
            "mizani==0.8.1\n",
            "mkl==2019.0\n",
            "ml-dtypes==0.1.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==9.1.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.0.5\n",
            "multidict==6.0.4\n",
            "multipledispatch==0.6.0\n",
            "multitasking==0.0.11\n",
            "murmurhash==1.0.9\n",
            "music21==8.1.0\n",
            "natsort==8.3.1\n",
            "nbclient==0.7.4\n",
            "nbconvert==6.5.4\n",
            "nbformat==5.8.0\n",
            "nest-asyncio==1.5.6\n",
            "networkx==3.1\n",
            "nibabel==3.0.2\n",
            "nltk==3.8.1\n",
            "notebook==6.4.8\n",
            "numba==0.56.4\n",
            "numexpr==2.8.4\n",
            "numpy==1.22.4\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.2\n",
            "opencv-contrib-python==4.7.0.72\n",
            "opencv-python==4.7.0.72\n",
            "opencv-python-headless==4.7.0.72\n",
            "openpyxl==3.0.10\n",
            "opt-einsum==3.3.0\n",
            "optax==0.1.5\n",
            "orbax-checkpoint==0.2.1\n",
            "osqp==0.6.2.post8\n",
            "packaging==23.1\n",
            "palettable==3.3.3\n",
            "pandas==1.5.3\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.17.9\n",
            "pandocfilters==1.5.0\n",
            "panel==0.14.4\n",
            "param==1.13.0\n",
            "parso==0.8.3\n",
            "partd==1.4.0\n",
            "pathlib==1.0.1\n",
            "pathy==0.10.1\n",
            "patsy==0.5.3\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==8.4.0\n",
            "pip-tools==6.13.0\n",
            "platformdirs==3.3.0\n",
            "plotly==5.13.1\n",
            "plotnine==0.10.1\n",
            "pluggy==1.0.0\n",
            "polars==0.17.3\n",
            "pooch==1.6.0\n",
            "portpicker==1.3.9\n",
            "prefetch-generator==1.0.3\n",
            "preshed==3.0.8\n",
            "prettytable==0.7.2\n",
            "proglog==0.1.10\n",
            "progressbar2==4.2.0\n",
            "prometheus-client==0.16.0\n",
            "promise==2.3\n",
            "prompt-toolkit==3.0.38\n",
            "prophet==1.1.3\n",
            "proto-plus==1.22.2\n",
            "protobuf==3.20.3\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.6\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==9.0.0\n",
            "pyasn1==0.5.0\n",
            "pyasn1-modules==0.3.0\n",
            "pycocotools==2.0.6\n",
            "pycparser==2.21\n",
            "pyct==0.5.0\n",
            "pydantic==1.10.7\n",
            "pydata-google-auth==1.7.0\n",
            "pydot==1.4.2\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyerfa==2.0.0.3\n",
            "pygame==2.3.0\n",
            "Pygments==2.14.0\n",
            "PyGObject==3.36.0\n",
            "PyJWT==2.7.0\n",
            "pymc==5.1.2\n",
            "PyMeeus==0.5.12\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.6\n",
            "pyparsing==3.0.9\n",
            "pyproject_hooks==1.0.0\n",
            "pyrsistent==0.19.3\n",
            "PySocks==1.7.1\n",
            "pytensor==2.10.1\n",
            "pytest==7.2.2\n",
            "python-apt==0.0.0\n",
            "python-dateutil==2.8.2\n",
            "python-louvain==0.16\n",
            "python-slugify==8.0.1\n",
            "python-utils==3.5.2\n",
            "pytz==2022.7.1\n",
            "pytz-deprecation-shim==0.1.0.post0\n",
            "pyviz-comms==2.2.1\n",
            "PyWavelets==1.4.1\n",
            "PyYAML==6.0\n",
            "pyzmq==23.2.1\n",
            "qdldl==0.1.7\n",
            "qudida==0.0.4\n",
            "regex==2022.10.31\n",
            "requests==2.27.1\n",
            "requests-oauthlib==1.3.1\n",
            "requests-unixsocket==0.2.0\n",
            "requirements-parser==0.5.0\n",
            "rich==13.3.4\n",
            "rpy2==3.5.5\n",
            "rsa==4.9\n",
            "scikit-image==0.19.3\n",
            "scikit-learn==1.2.2\n",
            "scipy==1.10.1\n",
            "scs==3.2.3\n",
            "seaborn==0.12.2\n",
            "Send2Trash==1.8.0\n",
            "shapely==2.0.1\n",
            "six==1.16.0\n",
            "sklearn-pandas==2.2.0\n",
            "smart-open==6.3.0\n",
            "sniffio==1.3.0\n",
            "snowballstemmer==2.2.0\n",
            "sortedcontainers==2.4.0\n",
            "soundfile==0.12.1\n",
            "soupsieve==2.4.1\n",
            "soxr==0.3.5\n",
            "spacy==3.5.2\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.4\n",
            "Sphinx==3.5.4\n",
            "sphinxcontrib-applehelp==1.0.4\n",
            "sphinxcontrib-devhelp==1.0.2\n",
            "sphinxcontrib-htmlhelp==2.0.1\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==1.0.3\n",
            "sphinxcontrib-serializinghtml==1.1.5\n",
            "SQLAlchemy==2.0.10\n",
            "sqlparse==0.4.4\n",
            "srsly==2.4.6\n",
            "statsmodels==0.13.5\n",
            "sympy==1.11.1\n",
            "tables==3.8.0\n",
            "tabulate==0.8.10\n",
            "tblib==1.7.0\n",
            "tenacity==8.2.2\n",
            "tensorboard==2.12.2\n",
            "tensorboard-data-server==0.7.0\n",
            "tensorboard-plugin-wit==1.8.1\n",
            "tensorflow==2.12.0\n",
            "tensorflow-datasets==4.9.2\n",
            "tensorflow-estimator==2.12.0\n",
            "tensorflow-gcs-config==2.12.0\n",
            "tensorflow-hub==0.13.0\n",
            "tensorflow-io-gcs-filesystem==0.32.0\n",
            "tensorflow-metadata==1.13.1\n",
            "tensorflow-probability==0.20.1\n",
            "tensorstore==0.1.36\n",
            "termcolor==2.3.0\n",
            "terminado==0.17.1\n",
            "text-unidecode==1.3\n",
            "textblob==0.17.1\n",
            "tf-slim==1.1.0\n",
            "thinc==8.1.9\n",
            "threadpoolctl==3.1.0\n",
            "tifffile==2023.4.12\n",
            "tinycss2==1.2.1\n",
            "toml==0.10.2\n",
            "tomli==2.0.1\n",
            "toolz==0.12.0\n",
            "torch @ https://download.pytorch.org/whl/cu118/torch-2.0.1%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=a7a49d459bf4862f64f7bc1a68beccf8881c2fa9f3e0569608e16ba6f85ebf7b\n",
            "torchaudio @ https://download.pytorch.org/whl/cu118/torchaudio-2.0.2%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=26692645ea061a005c57ec581a2d0425210ac6ba9f923edf11cc9b0ef3a111e9\n",
            "torchdata==0.6.1\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.15.2\n",
            "torchvision @ https://download.pytorch.org/whl/cu118/torchvision-0.15.2%2Bcu118-cp310-cp310-linux_x86_64.whl#sha256=19ca4ab5d6179bbe53cff79df1a855ee6533c2861ddc7389f68349d8b9f8302a\n",
            "tornado==6.3.1\n",
            "tqdm==4.65.0\n",
            "traitlets==5.7.1\n",
            "triton==2.0.0\n",
            "tweepy==4.13.0\n",
            "twilio==8.2.2\n",
            "typer==0.7.0\n",
            "types-setuptools==67.8.0.0\n",
            "typing_extensions==4.5.0\n",
            "tzdata==2023.3\n",
            "tzlocal==4.3\n",
            "uritemplate==4.1.1\n",
            "urllib3==1.26.15\n",
            "vega-datasets==0.9.0\n",
            "wasabi==1.1.1\n",
            "wcwidth==0.2.6\n",
            "webcolors==1.13\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.5.1\n",
            "Werkzeug==2.3.0\n",
            "widgetsnbextension==3.6.4\n",
            "wordcloud==1.8.2.2\n",
            "wrapt==1.14.1\n",
            "xarray==2022.12.0\n",
            "xarray-einstats==0.5.1\n",
            "xgboost==1.7.5\n",
            "xlrd==2.0.1\n",
            "yarl==1.9.2\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.18\n",
            "zict==3.0.0\n",
            "zipp==3.15.0\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmBSh4lAtZY/wPfzj3kZ6l",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}